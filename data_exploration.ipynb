{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration Data Lake\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:3.0.0-s_2.12\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = 'data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0      NaN  ...        U      NaN   1979.0  10282016    NaN    NaN     NaN   \n",
       "1      NaN  ...        Y      NaN   1991.0       D/S      M    NaN     NaN   \n",
       "2  20691.0  ...      NaN        M   1961.0  09302016      M    NaN      OS   \n",
       "3  20567.0  ...      NaN        M   1988.0  09302016    NaN    NaN      AA   \n",
       "4  20567.0  ...      NaN        M   2012.0  09302016    NaN    NaN      AA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  1.897628e+09    NaN       B2  \n",
       "1  3.736796e+09  00296       F1  \n",
       "2  6.666432e+08     93       B2  \n",
       "3  9.246846e+10  00199       B2  \n",
       "4  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv in data folder\n",
    "df.to_csv('data/i94_apr16_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a sample of the csv to the data folder\n",
    "df.sample(1000).to_csv('data/i94_apr16_sub_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:3.0.0-s_2.12\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"data/sas_data\")\n",
    "df_spark=spark.read.parquet(\"data/sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read immigration data\n",
    "imm_df = spark.read.format('com.github.saurfang.sas.spark').load('data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# immigration data schema\n",
    "imm_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|I94RES| count|\n",
      "+------+------+\n",
      "| 692.0| 42495|\n",
      "| 299.0|   792|\n",
      "| 576.0| 13992|\n",
      "| 735.0|   423|\n",
      "| 206.0|  8505|\n",
      "| 524.0|   519|\n",
      "| 389.0|    99|\n",
      "| 390.0|    76|\n",
      "| 249.0|  1310|\n",
      "| 329.0|   153|\n",
      "| 112.0|156613|\n",
      "| 154.0|   616|\n",
      "| 521.0|    19|\n",
      "| 124.0| 20245|\n",
      "| 438.0|112407|\n",
      "| 348.0|   137|\n",
      "| 410.0|    42|\n",
      "| 253.0|  2646|\n",
      "| 317.0|     9|\n",
      "| 128.0|    24|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | I94RES | 3 digit code for country of residence |\n",
    "imm_df.groupBy('I94RES').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|I94ADDR|count|\n",
      "+-------+-----+\n",
      "|     .N|    4|\n",
      "|     RG|    4|\n",
      "|     YH|    1|\n",
      "|     RF|    1|\n",
      "|     FT|    2|\n",
      "|     CI|   13|\n",
      "|     TC|    1|\n",
      "|     SC| 9811|\n",
      "|     AZ|20218|\n",
      "|     FI|    7|\n",
      "|     IC|    3|\n",
      "|     PU|   13|\n",
      "|     UA|   10|\n",
      "|     EA|    2|\n",
      "|     NS|   28|\n",
      "|     KI|   25|\n",
      "|     RO|    1|\n",
      "|     PI|    6|\n",
      "|     SL|    6|\n",
      "|     LA|22655|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | I94ADDR | state of arrival |\n",
    "imm_df.groupBy('I94ADDR').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|I94VISA|  count|\n",
      "+-------+-------+\n",
      "|    1.0| 522079|\n",
      "|    3.0|  43366|\n",
      "|    2.0|2530868|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | I94VISA | visa codes collapsed into three categories: 1 = Business; 2 = Pleasure; 3 = Student |\n",
    "imm_df.groupBy('I94VISA').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|I94PORT|count|\n",
      "+-------+-----+\n",
      "|    FMY|17514|\n",
      "|    BGM|  128|\n",
      "|    HEL|    2|\n",
      "|    DNS|   35|\n",
      "|    MOR|   14|\n",
      "|    FOK|   14|\n",
      "|    HVR|   45|\n",
      "|    SNA| 7066|\n",
      "|    PTK|   12|\n",
      "|    SPM|16973|\n",
      "|    CLG| 3191|\n",
      "|    OPF|  909|\n",
      "|    DLB|   12|\n",
      "|    ABS|    4|\n",
      "|    NAS|13032|\n",
      "|    MYR|    5|\n",
      "|    PVD|  352|\n",
      "|    OAK| 3501|\n",
      "|    FAR|    5|\n",
      "|    OTT|  663|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_df.groupBy('I94PORT').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|I94VISA|\n",
      "+-------+\n",
      "|    2.0|\n",
      "|    3.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    1.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    1.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    1.0|\n",
      "|    1.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "|    2.0|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_df.select('I94VISA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| I94YR|  count|\n",
      "+------+-------+\n",
      "|2016.0|3096313|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_df.groupBy('I94YR').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|INSNUM|count(GENDER)|\n",
      "+------+-------------+\n",
      "|  4032|            1|\n",
      "|  5325|            3|\n",
      "| 39645|            1|\n",
      "|  4821|            1|\n",
      "| 39590|            1|\n",
      "|  3414|            2|\n",
      "|  7252|            2|\n",
      "| 39458|            1|\n",
      "|   691|            1|\n",
      "|  3959|            1|\n",
      "|  3441|            3|\n",
      "|  3517|            4|\n",
      "|  3281|            3|\n",
      "| 38900|            1|\n",
      "|  5067|            1|\n",
      "|  3650|            2|\n",
      "|  3826|            1|\n",
      "|  5023|            2|\n",
      "|  1669|            3|\n",
      "|  5149|            3|\n",
      "+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gr = imm_df.groupBy(\"INSNUM\").agg(countDistinct(\"GENDER\"))\n",
    "gr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|count(GENDER)|count|\n",
      "+-------------+-----+\n",
      "|            1|  911|\n",
      "|            3|  266|\n",
      "|            2|  654|\n",
      "|            4|   83|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gr.groupBy('count(GENDER)').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|                 ts|\n",
      "+-------------------+\n",
      "|1970-01-01 05:42:53|\n",
      "|1970-01-01 05:42:31|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "|1970-01-01 05:42:25|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wrong date times, because its a SAS numeric time field\n",
    "from pyspark.sql.functions import col , column\n",
    "imm_df.withColumn(\"ts\", col(\"ARRDATE\").cast(\"timestamp\")).select('ts').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = spark.read.options(header='true', inferSchema='true').csv('data/GlobalLandTemperaturesByState.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|State|Country|\n",
      "+----------+------------------+-----------------------------+-----+-------+\n",
      "|1855-05-01|            25.544|                        1.171| Acre| Brazil|\n",
      "|1855-06-01|            24.228|                        1.103| Acre| Brazil|\n",
      "|1855-07-01|            24.371|                        1.044| Acre| Brazil|\n",
      "|1855-08-01|            25.427|                        1.073| Acre| Brazil|\n",
      "|1855-09-01|            25.675|                        1.014| Acre| Brazil|\n",
      "|1855-10-01|25.441999999999997|                        1.179| Acre| Brazil|\n",
      "|1855-11-01|              25.4|                        1.064| Acre| Brazil|\n",
      "|1855-12-01|              24.1|           1.7180000000000002| Acre| Brazil|\n",
      "|1856-01-01|            25.814|                        1.159| Acre| Brazil|\n",
      "|1856-02-01|            24.658|                        1.147| Acre| Brazil|\n",
      "+----------+------------------+-----------------------------+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|         State|count|\n",
      "+--------------+-----+\n",
      "|          Utah| 2298|\n",
      "|     Volgograd| 3239|\n",
      "|       Bryansk| 3239|\n",
      "|        Hawaii| 1569|\n",
      "|      Voronezh| 3239|\n",
      "|      Manitoba| 2941|\n",
      "|      Kostroma| 3239|\n",
      "|      Nagaland| 2371|\n",
      "|     Karnataka| 2613|\n",
      "|      Belgorod| 3239|\n",
      "|     Guangdong| 2085|\n",
      "|     Minnesota| 3239|\n",
      "|          Omsk| 2421|\n",
      "|Santa Catarina| 2181|\n",
      "|         Kursk| 3239|\n",
      "|          Ohio| 3239|\n",
      "|         Hunan| 2082|\n",
      "|        Kerala| 2613|\n",
      "|        Shanxi| 2318|\n",
      "|        Kaluga| 3239|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.groupBy('State').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "demo_df = spark.read.options(header='true', inferSchema='true', delimiter=';').csv('data/us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>34.6</td>\n",
       "      <td>192354</td>\n",
       "      <td>197601</td>\n",
       "      <td>389955</td>\n",
       "      <td>23978.0</td>\n",
       "      <td>40270.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>KS</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allen</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>33.5</td>\n",
       "      <td>60626</td>\n",
       "      <td>59581</td>\n",
       "      <td>120207</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>19652.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>PA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>22304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Danbury</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>37.3</td>\n",
       "      <td>43435</td>\n",
       "      <td>41227</td>\n",
       "      <td>84662</td>\n",
       "      <td>3752.0</td>\n",
       "      <td>25675.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>CT</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>34.1</td>\n",
       "      <td>314231</td>\n",
       "      <td>340365</td>\n",
       "      <td>654596</td>\n",
       "      <td>27942.0</td>\n",
       "      <td>88193.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>TN</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>67526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stamford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>35.4</td>\n",
       "      <td>64941</td>\n",
       "      <td>63936</td>\n",
       "      <td>128877</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>44003.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>CT</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>41.4</td>\n",
       "      <td>155408</td>\n",
       "      <td>186829</td>\n",
       "      <td>342237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>335559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Provo</td>\n",
       "      <td>Utah</td>\n",
       "      <td>23.6</td>\n",
       "      <td>56231</td>\n",
       "      <td>59027</td>\n",
       "      <td>115258</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>10925.0</td>\n",
       "      <td>3.28</td>\n",
       "      <td>UT</td>\n",
       "      <td>White</td>\n",
       "      <td>108471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Marcos</td>\n",
       "      <td>California</td>\n",
       "      <td>35.4</td>\n",
       "      <td>45246</td>\n",
       "      <td>47688</td>\n",
       "      <td>92934</td>\n",
       "      <td>5189.0</td>\n",
       "      <td>21558.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>4447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Escondido</td>\n",
       "      <td>California</td>\n",
       "      <td>33.3</td>\n",
       "      <td>76551</td>\n",
       "      <td>74907</td>\n",
       "      <td>151458</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>46298.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Caguas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>40.4</td>\n",
       "      <td>34743</td>\n",
       "      <td>42265</td>\n",
       "      <td>77008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>76349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City         State  Median Age  Male Population  Female Population  \\\n",
       "0     Wichita        Kansas        34.6           192354             197601   \n",
       "1       Allen  Pennsylvania        33.5            60626              59581   \n",
       "2     Danbury   Connecticut        37.3            43435              41227   \n",
       "3   Nashville     Tennessee        34.1           314231             340365   \n",
       "4    Stamford   Connecticut        35.4            64941              63936   \n",
       "5    San Juan   Puerto Rico        41.4           155408             186829   \n",
       "6       Provo          Utah        23.6            56231              59027   \n",
       "7  San Marcos    California        35.4            45246              47688   \n",
       "8   Escondido    California        33.3            76551              74907   \n",
       "9      Caguas   Puerto Rico        40.4            34743              42265   \n",
       "\n",
       "   Total Population  Number of Veterans  Foreign-born  Average Household Size  \\\n",
       "0            389955             23978.0       40270.0                    2.56   \n",
       "1            120207              5691.0       19652.0                    2.67   \n",
       "2             84662              3752.0       25675.0                    2.74   \n",
       "3            654596             27942.0       88193.0                    2.39   \n",
       "4            128877              2269.0       44003.0                    2.70   \n",
       "5            342237                 NaN           NaN                     NaN   \n",
       "6            115258              2177.0       10925.0                    3.28   \n",
       "7             92934              5189.0       21558.0                    3.13   \n",
       "8            151458              8110.0       46298.0                    3.27   \n",
       "9             77008                 NaN           NaN                     NaN   \n",
       "\n",
       "  State Code                               Race   Count  \n",
       "0         KS  American Indian and Alaska Native    8791  \n",
       "1         PA          Black or African-American   22304  \n",
       "2         CT          Black or African-American    8454  \n",
       "3         TN                 Hispanic or Latino   67526  \n",
       "4         CT                              Asian   11013  \n",
       "5         PR                 Hispanic or Latino  335559  \n",
       "6         UT                              White  108471  \n",
       "7         CA          Black or African-American    4447  \n",
       "8         CA  American Indian and Alaska Native    3151  \n",
       "9         PR                 Hispanic or Latino   76349  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport\n",
    "airport_df = spark.read.options(header='true', inferSchema='true').csv('data/airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|iso_country|count|\n",
      "+-----------+-----+\n",
      "|         DZ|   61|\n",
      "|         LT|   55|\n",
      "|         MM|   75|\n",
      "|         CI|   26|\n",
      "|         TC|   10|\n",
      "|         AZ|   35|\n",
      "|         FI|  111|\n",
      "|         SC|   18|\n",
      "|         PM|    2|\n",
      "|         UA|  191|\n",
      "|         ZM|  103|\n",
      "|         KI|   22|\n",
      "|         RO|   59|\n",
      "|         SL|   12|\n",
      "|         SB|   38|\n",
      "|         NL|   90|\n",
      "|         LA|   20|\n",
      "|         BS|   66|\n",
      "|         BW|  127|\n",
      "|         MN|   29|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.groupBy('iso_country').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.filter((airport_df[\"ident\"] == \"\") | airport_df[\"ident\"].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.groupBy('ident').count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immigration data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cicid to id\n",
    "# rename i94yr to year\n",
    "# rename i94mon to month\n",
    "# read mapping for code to country of origin, and map the I94CIT var to the actual country of origin (do later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_fact = imm_df.select(col(\"cicid\").alias(\"id\"),\n",
    "                          col(\"i94yr\").alias(\"year\"),\n",
    "                          col(\"i94mon\").alias(\"month\"),\n",
    "                          col(\"I94CIT\").alias(\"country_of_origin\"),\n",
    "                          col(\"I94ADDR\").alias(\"state_of_arrival\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+-----------------+----------------+\n",
      "|  id|  year|month|country_of_origin|state_of_arrival|\n",
      "+----+------+-----+-----------------+----------------+\n",
      "| 6.0|2016.0|  4.0|            692.0|            null|\n",
      "| 7.0|2016.0|  4.0|            254.0|              AL|\n",
      "|15.0|2016.0|  4.0|            101.0|              MI|\n",
      "|16.0|2016.0|  4.0|            101.0|              MA|\n",
      "|17.0|2016.0|  4.0|            101.0|              MA|\n",
      "|18.0|2016.0|  4.0|            101.0|              MI|\n",
      "|19.0|2016.0|  4.0|            101.0|              NJ|\n",
      "|20.0|2016.0|  4.0|            101.0|              NJ|\n",
      "|21.0|2016.0|  4.0|            101.0|              NY|\n",
      "|22.0|2016.0|  4.0|            101.0|              NY|\n",
      "|23.0|2016.0|  4.0|            101.0|              NY|\n",
      "|24.0|2016.0|  4.0|            101.0|              MO|\n",
      "|27.0|2016.0|  4.0|            101.0|              MA|\n",
      "|28.0|2016.0|  4.0|            101.0|              MA|\n",
      "|29.0|2016.0|  4.0|            101.0|              MA|\n",
      "|30.0|2016.0|  4.0|            101.0|              NJ|\n",
      "|31.0|2016.0|  4.0|            101.0|              NY|\n",
      "|33.0|2016.0|  4.0|            101.0|              TX|\n",
      "|34.0|2016.0|  4.0|            101.0|              CT|\n",
      "|35.0|2016.0|  4.0|            101.0|              CT|\n",
      "+----+------+-----+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_fact.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_dim = imm_df.select(col(\"cicid\").alias(\"id\"),\n",
    "                          col(\"GENDER\").alias(\"gender\"),\n",
    "                          col(\"I94BIR\").alias(\"I94BIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+\n",
      "|  id|gender|I94BIR|\n",
      "+----+------+------+\n",
      "| 6.0|  null|  37.0|\n",
      "| 7.0|     M|  25.0|\n",
      "|15.0|     M|  55.0|\n",
      "|16.0|  null|  28.0|\n",
      "|17.0|  null|   4.0|\n",
      "|18.0|  null|  57.0|\n",
      "|19.0|  null|  63.0|\n",
      "|20.0|  null|  57.0|\n",
      "|21.0|  null|  46.0|\n",
      "|22.0|  null|  48.0|\n",
      "|23.0|  null|  52.0|\n",
      "|24.0|  null|  33.0|\n",
      "|27.0|     M|  58.0|\n",
      "|28.0|     F|  56.0|\n",
      "|29.0|     M|  62.0|\n",
      "|30.0|     M|  49.0|\n",
      "|31.0|     M|  43.0|\n",
      "|33.0|     F|  53.0|\n",
      "|34.0|     M|  48.0|\n",
      "|35.0|     F|  74.0|\n",
      "+----+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_dim.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|     City|       State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+---------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|  Wichita|      Kansas|      34.6|         192354|           197601|          389955|             23978|       40270|                  2.56|        KS|American Indian a...| 8791|\n",
      "|    Allen|Pennsylvania|      33.5|          60626|            59581|          120207|              5691|       19652|                  2.67|        PA|Black or African-...|22304|\n",
      "|  Danbury| Connecticut|      37.3|          43435|            41227|           84662|              3752|       25675|                  2.74|        CT|Black or African-...| 8454|\n",
      "|Nashville|   Tennessee|      34.1|         314231|           340365|          654596|             27942|       88193|                  2.39|        TN|  Hispanic or Latino|67526|\n",
      "| Stamford| Connecticut|      35.4|          64941|            63936|          128877|              2269|       44003|                   2.7|        CT|               Asian|11013|\n",
      "+---------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = demo_df.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_dim = demo_df.select(col(\"id\"),\n",
    "                                  col(\"State\").alias(\"state\"),\n",
    "                                  col(\"MEDIAN AGE\").alias(\"median_age\"),\n",
    "                                  col(\"Total Population\").alias(\"total_population\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+----------------+\n",
      "| id|       state|median_age|total_population|\n",
      "+---+------------+----------+----------------+\n",
      "|  0|      Kansas|      34.6|          389955|\n",
      "|  1|Pennsylvania|      33.5|          120207|\n",
      "|  2| Connecticut|      37.3|           84662|\n",
      "|  3|   Tennessee|      34.1|          654596|\n",
      "|  4| Connecticut|      35.4|          128877|\n",
      "+---+------------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>None</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>None</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>3038</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>00CA</td>\n",
       "      <td>None</td>\n",
       "      <td>00CA</td>\n",
       "      <td>-116.888000488, 35.350498199499995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>87</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>00CL</td>\n",
       "      <td>None</td>\n",
       "      <td>00CL</td>\n",
       "      <td>-121.763427, 39.427188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kitchen Creek Helibase Heliport</td>\n",
       "      <td>3350</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>00CN</td>\n",
       "      <td>None</td>\n",
       "      <td>00CN</td>\n",
       "      <td>-116.4597417, 32.7273736</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport            11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          3435   \n",
       "2  00AK  small_airport                        Lowell Field           450   \n",
       "3  00AL  small_airport                        Epps Airpark           820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport           237   \n",
       "5  00AS  small_airport                      Fulton Airport          1100   \n",
       "6  00AZ  small_airport                      Cordes Airport          3810   \n",
       "7  00CA  small_airport             Goldstone /Gts/ Airport          3038   \n",
       "8  00CL  small_airport                 Williams Ag Airport            87   \n",
       "9  00CN       heliport     Kitchen Creek Helibase Heliport          3350   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "5        NA          US      US-OK          Alex     00AS      None   \n",
       "6        NA          US      US-AZ        Cordes     00AZ      None   \n",
       "7        NA          US      US-CA       Barstow     00CA      None   \n",
       "8        NA          US      US-CA         Biggs     00CL      None   \n",
       "9        NA          US      US-CA   Pine Valley     00CN      None   \n",
       "\n",
       "  local_code                              coordinates  id  \n",
       "0        00A       -74.93360137939453, 40.07080078125   0  \n",
       "1       00AA                   -101.473911, 38.704022   1  \n",
       "2       00AK              -151.695999146, 59.94919968   2  \n",
       "3       00AL    -86.77030181884766, 34.86479949951172   3  \n",
       "4       None                      -91.254898, 35.6087   4  \n",
       "5       00AS                  -97.8180194, 34.9428028   5  \n",
       "6       00AZ  -112.16500091552734, 34.305599212646484   6  \n",
       "7       00CA       -116.888000488, 35.350498199499995   7  \n",
       "8       00CL                   -121.763427, 39.427188   8  \n",
       "9       00CN                 -116.4597417, 32.7273736   9  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_dim = airport_df.select(col(\"ident\").alias(\"id\"),\n",
    "                                  col(\"iso_country\").alias(\"country\"),\n",
    "                                  col(\"MEDIAN AGE\").alias(\"median_age\"),\n",
    "                                  col(\"Total Population\").alias(\"total_population\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create country code mapping table using the I94 description file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"data/i94_country_code_mapping.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(np.nan, '', regex=True)\n",
    "cols = [1,2,3,4,5,6,7,8,9,10]\n",
    "df['country'] = df[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "df = df[[0, 'country']]\n",
    "df.columns = ['code', 'country']\n",
    "df = df[df['code'] != '']\n",
    "df['code'] = df['code'].astype(int)\n",
    "df.to_csv('data/code_to_country_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, create_map, lit, expr, to_date\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-778261c4d02e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.jars.packages\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menableHiveSupport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dc70590ffb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read all tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimmigration_staging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/i94_apr16_sub_sample.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcountry_code_mapping_staging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/code_to_country_mapping.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdemographics_staging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/us-cities-demographics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mweather_staging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/GlobalLandTemperaturesByState.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Read all tables\n",
    "immigration_staging = spark.read.options(header='true', inferSchema='true').csv('data/i94_apr16_sub_sample.csv')\n",
    "country_code_mapping_staging = spark.read.options(header='true', inferSchema='true').csv('data/code_to_country_mapping.csv')\n",
    "demographics_staging = spark.read.options(header='true', inferSchema='true', delimiter=';').csv('data/us-cities-demographics.csv')\n",
    "weather_staging = spark.read.options(header='true', inferSchema='true').csv('data/GlobalLandTemperaturesByState.csv')\n",
    "airport_staging = spark.read.options(header='true', inferSchema='true').csv('data/airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transportation_mapping = {1: 'air', 2: 'sea', 3: 'land', 4: 'not reported'}\n",
    "transportation_mapping_expr = create_map([lit(x) for x in chain(*transportation_mapping.items())])\n",
    "\n",
    "state_mapping = {'AL':'ALABAMA',\n",
    "                    'AK':'ALASKA',\n",
    "                    'AZ':'ARIZONA',\n",
    "                    'AR':'ARKANSAS',\n",
    "                    'CA':'CALIFORNIA',\n",
    "                    'CO':'COLORADO',\n",
    "                    'CT':'CONNECTICUT',\n",
    "                    'DE':'DELAWARE',\n",
    "                    'DC':'DIST. OF COLUMBIA',\n",
    "                    'FL':'FLORIDA',\n",
    "                    'GA':'GEORGIA',\n",
    "                    'GU':'GUAM',\n",
    "                    'HI':'HAWAII',\n",
    "                    'ID':'IDAHO',\n",
    "                    'IL':'ILLINOIS',\n",
    "                    'IN':'INDIANA',\n",
    "                    'IA':'IOWA',\n",
    "                    'KS':'KANSAS',\n",
    "                    'KY':'KENTUCKY',\n",
    "                    'LA':'LOUISIANA',\n",
    "                    'ME':'MAINE',\n",
    "                    'MD':'MARYLAND',\n",
    "                    'MA':'MASSACHUSETTS',\n",
    "                    'MI':'MICHIGAN',\n",
    "                    'MN':'MINNESOTA',\n",
    "                    'MS':'MISSISSIPPI',\n",
    "                    'MO':'MISSOURI',\n",
    "                    'MT':'MONTANA',\n",
    "                    'NC':'N. CAROLINA',\n",
    "                    'ND':'N. DAKOTA',\n",
    "                    'NE':'NEBRASKA',\n",
    "                    'NV':'NEVADA',\n",
    "                    'NH':'NEW HAMPSHIRE',\n",
    "                    'NJ':'NEW JERSEY',\n",
    "                    'NM':'NEW MEXICO',\n",
    "                    'NY':'NEW YORK',\n",
    "                    'OH':'OHIO',\n",
    "                    'OK':'OKLAHOMA',\n",
    "                    'OR':'OREGON',\n",
    "                    'PA':'PENNSYLVANIA',\n",
    "                    'PR':'PUERTO RICO',\n",
    "                    'RI':'RHODE ISLAND',\n",
    "                    'SC':'S. CAROLINA',\n",
    "                    'SD':'S. DAKOTA',\n",
    "                    'TN':'TENNESSEE',\n",
    "                    'TX':'TEXAS',\n",
    "                    'UT':'UTAH',\n",
    "                    'VT':'VERMONT',\n",
    "                    'VI':'VIRGIN ISLANDS',\n",
    "                    'VA':'VIRGINIA',\n",
    "                    'WV':'W. VIRGINIA',\n",
    "                    'WA':'WASHINGTON',\n",
    "                    'WI':'WISCONSON',\n",
    "                    'WY':'WYOMING' ,\n",
    "                    '99':'All Other Codes'}\n",
    "state_mapping = dict((k, v.title()) for k, v in state_mapping.items())\n",
    "state_mapping_expr = create_map([lit(x) for x in chain(*state_mapping.items())])\n",
    "\n",
    "visa_mapping = {1: 'business', 2: 'pleasure', 3: 'student'}\n",
    "visa_mapping_expr = create_map([lit(x) for x in chain(*visa_mapping.items())])\n",
    "\n",
    "immigration_fact =  immigration_staging.select(col(\"cicid\").alias(\"id\").cast(\"int\"),\n",
    "                    col(\"I94YR\").alias(\"year\").cast(\"int\"),\n",
    "                    col(\"I94MON\").alias(\"month\").cast(\"int\"),\n",
    "                    col(\"I94PORT\").alias(\"port_of_entry\"),\n",
    "                    col(\"ARRDATE\").alias(\"arrival_date\").cast(\"int\"),\n",
    "                    col(\"I94MODE\").alias(\"mode_of_transportation\").cast(\"int\"),\n",
    "                    col(\"I94ADDR\").alias(\"state_of_arrival_code\"),\n",
    "                    col(\"DEPDATE\").alias(\"departure_date\").cast(\"int\"),\n",
    "                    col(\"I94VISA\").alias(\"visa_type\").cast(\"int\"),) \\\n",
    ".withColumn(\"mode_of_transportation\", transportation_mapping_expr[col(\"mode_of_transportation\")]) \\\n",
    ".withColumn(\"state_of_arrival\", state_mapping_expr[col(\"state_of_arrival_code\")]) \\\n",
    ".withColumn(\"sas_date\", to_date(lit(\"01/01/1960\"), \"MM/dd/yyyy\")) \\\n",
    ".withColumn(\"arrival_date\", expr(\"date_add(sas_date, arrival_date)\")) \\\n",
    ".withColumn(\"departure_date\", expr(\"date_add(sas_date, departure_date)\")) \\\n",
    ".withColumn(\"visa_type\", visa_mapping_expr[col(\"visa_type\")]) \\\n",
    ".drop('sas_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'immigration_fact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-61bbbcb45e82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimmigration_fact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'immigration_fact' is not defined"
     ]
    }
   ],
   "source": [
    "immigration_fact.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_dim = immigration_staging.join(country_code_mapping_staging, \n",
    "                         immigration_staging[\"I94CIT\"] == country_code_mapping_staging[\"code\"], \n",
    "                         \"left\").withColumnRenamed(\"country\", \"country_of_origin\").drop('code')\n",
    "person_dim = person_dim.join(country_code_mapping_staging, \n",
    "                         person_dim[\"I94RES\"] == country_code_mapping_staging[\"code\"], \n",
    "                         \"left\").withColumnRenamed(\"country\", \"country_of_residence\").drop('code')\n",
    "person_dim = person_dim.select(col(\"cicid\").alias(\"id\").cast(\"int\"),\n",
    "                                            col(\"GENDER\").alias(\"gender\"),\n",
    "                                            col(\"I94BIR\").alias(\"age\").cast(\"int\"),\n",
    "                                            col(\"country_of_origin\").alias(\"country_of_origin\"),\n",
    "                                            col(\"country_of_residence\").alias(\"country_of_residence\"),\n",
    "                                            col(\"BIRYEAR\").alias(\"year_of_birth\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+--------------------+--------------------+-------------+\n",
      "|     id|gender|age|   country_of_origin|country_of_residence|year_of_birth|\n",
      "+-------+------+---+--------------------+--------------------+-------------+\n",
      "|5451672|     M| 52|'UNITED KINGDOM' ...|'UNITED KINGDOM' ...|         1964|\n",
      "|6096389|     M| 35|'MEXICO Air Sea, ...|'MEXICO Air Sea, ...|         1981|\n",
      "|3686942|     M| 63|                null|  'GERMANY'         |         1953|\n",
      "|1579708|     M| 51|'NETHERLANDS'    ...|'NETHERLANDS'    ...|         1965|\n",
      "| 829755|     M| 70|  'ROMANIA'         |  'ROMANIA'         |         1946|\n",
      "+-------+------+---+--------------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics dimension\n",
    "demographics_dim = demographics_staging.withColumn(\"id\", monotonically_increasing_id()) \\\n",
    "                    .select(col(\"id\"),\n",
    "                            col(\"State\").alias(\"state\"),\n",
    "                            col(\"Median Age\").alias(\"median_age\"),\n",
    "                            col(\"Female Population\").alias(\"female_population\"),\n",
    "                            col(\"Number of Veterans\").alias(\"number_of_veterans\"),\n",
    "                            col(\"Foreign-born\").alias(\"foreign_born\"),\n",
    "                            col(\"Average Household Size\").alias(\"average_household_size\"),\n",
    "                            col(\"State Code\").alias(\"state_code\"),\n",
    "                            col(\"Race\").alias(\"race\"),\n",
    "                            col(\"Count\").alias(\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+-----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "| id|       state|median_age|female_population|number_of_veterans|foreign_born|average_household_size|state_code|                race|count|\n",
      "+---+------------+----------+-----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|  0|      Kansas|      34.6|           197601|             23978|       40270|                  2.56|        KS|American Indian a...| 8791|\n",
      "|  1|Pennsylvania|      33.5|            59581|              5691|       19652|                  2.67|        PA|Black or African-...|22304|\n",
      "|  2| Connecticut|      37.3|            41227|              3752|       25675|                  2.74|        CT|Black or African-...| 8454|\n",
      "|  3|   Tennessee|      34.1|           340365|             27942|       88193|                  2.39|        TN|  Hispanic or Latino|67526|\n",
      "|  4| Connecticut|      35.4|            63936|              2269|       44003|                   2.7|        CT|               Asian|11013|\n",
      "+---+------------+----------+-----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- number_of_veterans: integer (nullable = true)\n",
      " |-- foreign_born: integer (nullable = true)\n",
      " |-- average_household_size: double (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dim = weather_staging.withColumn(\"id\", monotonically_increasing_id()) \\\n",
    "                              .select(col(\"id\"),\n",
    "                                     col(\"dt\").alias(\"date\"),\n",
    "                                     col(\"AverageTemperature\").alias(\"average_temperature\"),\n",
    "                                     col(\"AverageTemperatureUncertainty\").alias(\"average_temperature_uncertainty\"),\n",
    "                                     col(\"State\").alias(\"state\"),\n",
    "                                     col(\"Country\").alias(\"country\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------------+-------------------------------+-----+-------+\n",
      "| id|      date|average_temperature|average_temperature_uncertainty|state|country|\n",
      "+---+----------+-------------------+-------------------------------+-----+-------+\n",
      "|  0|1855-05-01|             25.544|                          1.171| Acre| Brazil|\n",
      "|  1|1855-06-01|             24.228|                          1.103| Acre| Brazil|\n",
      "|  2|1855-07-01|             24.371|                          1.044| Acre| Brazil|\n",
      "|  3|1855-08-01|             25.427|                          1.073| Acre| Brazil|\n",
      "|  4|1855-09-01|             25.675|                          1.014| Acre| Brazil|\n",
      "+---+----------+-------------------+-------------------------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_dim = airport_staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_staging.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# airport_staging.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
